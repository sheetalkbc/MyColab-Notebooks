{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer & Autoencoder.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyc08RXFkCSdGrETwvG9ks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheetalkbc/MyColab-Notebooks/blob/master/Transformer_%26_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqKyGqUXVkpP"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fWMYJgVxHHf"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54gnUAa0Yt2F"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-yLNyQ_Y1UT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import FeatureExtractionPipeline,AutoTokenizer,AutoModel,Pipeline\n",
        "import transformers\n",
        "import tqdm\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw1wwleMZOZc"
      },
      "source": [
        "#from google.colab import files\n",
        "#import io\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#df = pd.read_csv(io.StringIO(uploaded['TruckRoll.csv'].decode('utf-8')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zddMXmGGpN1Q"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/sheetalkbc/TestDataFiles/main/TruckRoll.csv?token=AJU6QFGGJUHYDPCKXFHHQUTA52EO4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6WMnp5JrFrP"
      },
      "source": [
        "df.drop('Unnamed: 0',inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vboSIdP5grSt"
      },
      "source": [
        "F_model = AutoModel.from_pretrained(\"xlm-roberta-large-finetuned-conll03-german\",output_hidden_states=True)\n",
        "F_Tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large-finetuned-conll03-german\",use_fast=True,max_len=512)\n",
        "\n",
        "pipe = FeatureExtractionPipeline(F_model,F_Tokenizer,device=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGYz-N_vuP3H"
      },
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS1vbXDZrVAH"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/stsb-xlm-r-multilingual')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Dz3BPuyMsG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prIiiM9RyRAO"
      },
      "source": [
        "df_nonConfigIssue = df.text.loc[df.labels==0]\n",
        "df_ConfigIssue = df.text.loc[df.labels==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bHof7eUk4ZU"
      },
      "source": [
        "batch_size = 64\n",
        "features = np.empty((0,768), float)\n",
        "\n",
        "for i in tqdm.tqdm(range(0, df_nonConfigIssue.shape[0], batch_size)):\n",
        "    batch = df_nonConfigIssue.tolist()[i:i+batch_size]\n",
        "    feature_list = model.encode(batch)\n",
        "    Arr = np.array(feature_list)\n",
        "    features = np.append(features,Arr,axis=0)\n",
        "\n",
        "np.shape(features)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuY3QZnKsz9X"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6M65Ufyy9pv"
      },
      "source": [
        "AutoEncoderModel = keras.Sequential(\n",
        "    [\n",
        "      layers.InputLayer(input_shape=(768,)),\n",
        "        layers.Dense(768,activation=\"relu\"),\n",
        "        layers.Dense(700,activation=\"relu\"),\n",
        "        layers.Dense(350,activation=\"relu\"),\n",
        "        layers.Dense(700,activation=\"relu\"),\n",
        "        layers.Dense(768,activation=\"relu\"),\n",
        "    ]\n",
        ")\n",
        "AutoEncoderModel.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "AutoEncoderModel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP6ueAxT0rFx"
      },
      "source": [
        "history = AutoEncoderModel.fit(\n",
        "    features,\n",
        "    features,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
        "    ],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwzr_Ihi2KMq"
      },
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_LwYkMa24v-"
      },
      "source": [
        "# Get train MAE loss.\n",
        "x_train_pred = AutoEncoderModel.predict(features)\n",
        "train_mae_loss = np.mean(np.abs(x_train_pred - features), axis=1)\n",
        "\n",
        "plt.hist(train_mae_loss, bins=50)\n",
        "plt.xlabel(\"Train MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction loss threshold.\n",
        "threshold = np.max(train_mae_loss)\n",
        "print(\"Reconstruction error threshold: \", threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPPjn0a-3z_Y"
      },
      "source": [
        "anomalies = train_mae_loss > threshold\n",
        "np.where(anomalies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR4QOnkp7zyG"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge7z5BV94Bgm"
      },
      "source": [
        "Config_features = model.encode(df_ConfigIssue.tolist())\n",
        "\n",
        "x_test_pred = AutoEncoderModel.predict(Config_features)\n",
        "test_mae_loss = np.mean(np.abs(x_test_pred - Config_features), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihjezTmp8bVP"
      },
      "source": [
        "plt.hist(test_mae_loss, bins=50)\n",
        "plt.xlabel(\"Train MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction loss threshold.\n",
        "threshold = np.max(test_mae_loss)\n",
        "print(\"Reconstruction error threshold: \", threshold)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}